{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.05333917524300281,
  "eval_steps": 500,
  "global_step": 1400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0019049705443929573,
      "grad_norm": 1.2880706787109375,
      "learning_rate": 6.218274111675127e-06,
      "loss": 3.1815,
      "step": 50
    },
    {
      "epoch": 0.0038099410887859147,
      "grad_norm": 0.6035448312759399,
      "learning_rate": 1.2563451776649746e-05,
      "loss": 2.8102,
      "step": 100
    },
    {
      "epoch": 0.005714911633178872,
      "grad_norm": 0.3557184636592865,
      "learning_rate": 1.8908629441624368e-05,
      "loss": 2.3784,
      "step": 150
    },
    {
      "epoch": 0.007619882177571829,
      "grad_norm": 0.26012980937957764,
      "learning_rate": 2.5253807106598986e-05,
      "loss": 2.1374,
      "step": 200
    },
    {
      "epoch": 0.009524852721964787,
      "grad_norm": 0.2703339159488678,
      "learning_rate": 3.1598984771573604e-05,
      "loss": 2.0599,
      "step": 250
    },
    {
      "epoch": 0.011429823266357744,
      "grad_norm": 0.27892422676086426,
      "learning_rate": 3.794416243654822e-05,
      "loss": 2.0264,
      "step": 300
    },
    {
      "epoch": 0.013334793810750702,
      "grad_norm": 0.2735331356525421,
      "learning_rate": 4.428934010152285e-05,
      "loss": 2.0623,
      "step": 350
    },
    {
      "epoch": 0.015239764355143659,
      "grad_norm": 0.26665645837783813,
      "learning_rate": 5.063451776649747e-05,
      "loss": 2.0602,
      "step": 400
    },
    {
      "epoch": 0.017144734899536617,
      "grad_norm": 0.2764730751514435,
      "learning_rate": 5.697969543147208e-05,
      "loss": 2.0339,
      "step": 450
    },
    {
      "epoch": 0.019049705443929574,
      "grad_norm": 0.2954251170158386,
      "learning_rate": 6.33248730964467e-05,
      "loss": 2.0203,
      "step": 500
    },
    {
      "epoch": 0.02095467598832253,
      "grad_norm": 0.32936930656433105,
      "learning_rate": 6.967005076142133e-05,
      "loss": 1.9786,
      "step": 550
    },
    {
      "epoch": 0.022859646532715487,
      "grad_norm": 0.2733890414237976,
      "learning_rate": 7.601522842639595e-05,
      "loss": 1.9807,
      "step": 600
    },
    {
      "epoch": 0.024764617077108444,
      "grad_norm": 0.27097088098526,
      "learning_rate": 8.236040609137056e-05,
      "loss": 1.9874,
      "step": 650
    },
    {
      "epoch": 0.026669587621501404,
      "grad_norm": 0.2992316484451294,
      "learning_rate": 8.870558375634518e-05,
      "loss": 2.0364,
      "step": 700
    },
    {
      "epoch": 0.02857455816589436,
      "grad_norm": 0.30972373485565186,
      "learning_rate": 9.50507614213198e-05,
      "loss": 2.0015,
      "step": 750
    },
    {
      "epoch": 0.030479528710287317,
      "grad_norm": 0.28803157806396484,
      "learning_rate": 9.995679497250589e-05,
      "loss": 2.0126,
      "step": 800
    },
    {
      "epoch": 0.032384499254680274,
      "grad_norm": 0.28980737924575806,
      "learning_rate": 9.976040848389632e-05,
      "loss": 1.9941,
      "step": 850
    },
    {
      "epoch": 0.034289469799073234,
      "grad_norm": 0.2769056558609009,
      "learning_rate": 9.956402199528673e-05,
      "loss": 2.0228,
      "step": 900
    },
    {
      "epoch": 0.03619444034346619,
      "grad_norm": 0.29960811138153076,
      "learning_rate": 9.936763550667715e-05,
      "loss": 2.0213,
      "step": 950
    },
    {
      "epoch": 0.03809941088785915,
      "grad_norm": 0.2705684304237366,
      "learning_rate": 9.917124901806756e-05,
      "loss": 2.0121,
      "step": 1000
    },
    {
      "epoch": 0.0400043814322521,
      "grad_norm": 0.2963111996650696,
      "learning_rate": 9.897486252945798e-05,
      "loss": 2.0253,
      "step": 1050
    },
    {
      "epoch": 0.04190935197664506,
      "grad_norm": 0.2981192171573639,
      "learning_rate": 9.877847604084839e-05,
      "loss": 2.0072,
      "step": 1100
    },
    {
      "epoch": 0.04381432252103802,
      "grad_norm": 0.25020381808280945,
      "learning_rate": 9.85820895522388e-05,
      "loss": 2.0089,
      "step": 1150
    },
    {
      "epoch": 0.045719293065430974,
      "grad_norm": 0.2400648444890976,
      "learning_rate": 9.838570306362923e-05,
      "loss": 1.9919,
      "step": 1200
    },
    {
      "epoch": 0.047624263609823934,
      "grad_norm": 0.2731578052043915,
      "learning_rate": 9.818931657501963e-05,
      "loss": 2.001,
      "step": 1250
    },
    {
      "epoch": 0.04952923415421689,
      "grad_norm": 0.2633461058139801,
      "learning_rate": 9.799293008641006e-05,
      "loss": 2.0267,
      "step": 1300
    },
    {
      "epoch": 0.05143420469860985,
      "grad_norm": 0.2965903878211975,
      "learning_rate": 9.779654359780048e-05,
      "loss": 2.019,
      "step": 1350
    },
    {
      "epoch": 0.05333917524300281,
      "grad_norm": 0.2664187252521515,
      "learning_rate": 9.760015710919089e-05,
      "loss": 1.9729,
      "step": 1400
    }
  ],
  "logging_steps": 50,
  "max_steps": 26248,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.5436894658330624e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
